{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution is one of the most important layers used in image processing based problems. On the other it is also one of the most computationally demanding layer. This tutorial explains how convolution works and we discuss the backpropagation through the convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward direction (inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![conv](https://img.youtube.com/vi/wUp5hx-onUI/0.jpg)](https://www.youtube.com/watch?v=wUp5hx-onUI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video above illustrates how a 2D convolution works in case of a simple case. We can consider as a usual fully connected layer but there are shared weights. In a fully connected layer all the weights are independent (can be adjusted independently) but in a convolution layer each weight is reused among more neurons. \n",
    "\n",
    "A convolution has the following components (and charasteristics):\n",
    "* kernel (sometimes called filters)\n",
    "* stride\n",
    "* padding\n",
    "* dilation.\n",
    "\n",
    "The **kernel** is a 4 dimensional tensor which contains the weights to be tuned. Basically it is a window which will hover over the input (image) as the video shows. The four dimensions are: 1) the number of filters, 2) the height of the window, 3) the width of the window and 4) the channel. Generally the number of channels are the same as the number of the channels of the input. \n",
    "\n",
    "The **stride** defines how the kernel slides in two dimensions (height, width). In each step the kernel is moved away from the current position to the next one according to the slide. For instance, when the stride is (1, 1) that means the kernel moves to the neighboring input value on the right and at the end of a row (of pixels) it moves down by 1 row. If the stride is (2, 1) it means that the window moves by 2 rows down when a row ends and 1 column right in each step. The video is an example for stride (1, 1).\n",
    "\n",
    "The **padding** means if at the borders there are additional values (pixels) added artificially to the original input in order to increase its size. In the most general case during padding the amount of element added each side of the image can be different and the padding value can be set as well. In deep learning padding can be VALID and SAME. Most of the libraries like tensorflow or pytorch provides them. VALID means basically there is no padding. SAME means after applying the convolution the output has the same size as the input. Without padding this is not possible with kernel size greater than 1. The amount of padding should be chosen in a way that the output size will not change. The padding value is zero.\n",
    "\n",
    "**Dilation** is rarely used in practice but sometimes it can be still useful. The kernel can be concise in the sense that the distance between the elements of the kernel is 1. But it can be bigger which can cause a bigger preceptive field.  \n",
    "\n",
    "For the sake of simplicity here is the formula of convolution with padding VALID, stride (1, 1) and dilation (0, 0):\n",
    "\n",
    "\\begin{equation}\n",
    "O_{b, i, j, f} = \\sum_{k_i, k_j, k_c}{I_{b, i + k_i, j + k_j, c + k_c} \\cdot K_{f, k_i, k_j, k_c}}.\n",
    "\\end{equation}\n",
    "\n",
    "$b$ is the batch index, and the other indices are indices in the corresponding dimensions. The reason why this is a convolution, let's see another formula for convolution but with 1 dimensional, continuous functions:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left(f * g \\right)(z) = \\int_x{f(z - x) \\cdot g(x) dx}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True # this line is for autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.cnn_base import Convolution\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming example for convolution (forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 3, 3, 2)\n",
    "filters = 1\n",
    "kernel_size = (2, 2)\n",
    "strides = (1, 1)\n",
    "dilations = (0, 0)\n",
    "padding = 'SAME'\n",
    "conv = Convolution(input_shape, filters, kernel_size, strides, dilations, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a kernel full of with 1s\n",
    "conv.kernel = np.ones((1, 2, 2, 2))\n",
    "\n",
    "# create the input tensor\n",
    "x = np.zeros((1, 3, 3, 2))\n",
    "x[0, :, :, 0] = np.array([[2, 1, 1.5], [3, 2.2, 5], [5, 3, 2]])\n",
    "x[0, :, :, 1] = np.array([[7.3, 4, 2], [4, 3, 2], [0.8, 2.7, 3.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.output_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[26.5]\n",
      "   [20.7]\n",
      "   [10.5]]\n",
      "\n",
      "  [[23.7]\n",
      "   [23.8]\n",
      "   [12.9]]\n",
      "\n",
      "  [[11.5]\n",
      "   [11.6]\n",
      "   [ 5.9]]]]\n"
     ]
    }
   ],
   "source": [
    "y = conv(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward calculation can be speed up by different methods like Winogard. See for example: [Winogard](https://arxiv.org/abs/1509.09308)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward (backpropagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training we need the rightgradients in order to alter the current parameters. The gradient is given by the following formula after applying the chain rule.\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial L}{\\partial K_{f, k_i, k_j, k_c}} = \\sum_{b, i, j}{\\frac{\\partial L}{\\partial O_{b, i, j, f}} \\frac{\\partial O_{b, i, j, f}}{\\partial K_{f, k_i, k_j, k_c}} } = \\sum_{b, i, j}{\\frac{\\partial L}{\\partial O_{b, i, j, f}} \\cdot I_{b, i + k_i, j + k_j, c + k_c} }\n",
    "\\end{equation}\n",
    "\n",
    "In the last expression the first term comes from the previous derivatives. Therefore the gradient of the convolution (J) can be written as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "J^{b, i, j}_{k_i, k_j, k_c, c} = I_{b, i + k_i, j + k_j, c + k_c}.\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reference implementation can be found in the cnn.cnn_backward module. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
